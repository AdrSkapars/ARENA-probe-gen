{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02899f49",
   "metadata": {},
   "source": [
    "# Probe Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6fd824",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# If getting 'Could not find project LASR_probe_gen' get key from https://wandb.ai/authorize and paste below\n",
    "import os\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "import wandb\n",
    "wandb.login(key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20bb32e",
   "metadata": {},
   "source": [
    "## Do probe training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729248f5",
   "metadata": {},
   "source": [
    "Load the activations and labels from HF, aggregate, and construct datasets to train the probe on (note sklearn doesn't require a validation dataset). Create a probe and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import probe_gen.probes as probes\n",
    "from sklearn.metrics import classification_report\n",
    "from probe_gen.config import ConfigDict\n",
    "\n",
    "# Load the best hyperparameters or set your own\n",
    "probe_type = \"mean\"\n",
    "dataset_name = \"refusal_llama_3b_5k\"\n",
    "cfg = ConfigDict.from_json(probe_type, dataset_name)\n",
    "# cfg = ConfigDict(layer=12, use_bias=True, normalize=True, c=0.001)\n",
    "\n",
    "# Create train, val, and test datasets\n",
    "activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(dataset_name, layer=cfg.layer, verbose=True)\n",
    "if probe_type == \"mean\":\n",
    "    activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "train_dataset, val_dataset, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, splits=[3500, 500, 0], verbose=True)\n",
    "\n",
    "# Initialise and fit a probe with the datasets\n",
    "if probe_type == \"mean_torch\":\n",
    "    probe = probes.TorchLinearProbe(cfg)\n",
    "elif probe_type == \"attention_torch\":\n",
    "    probe = probes.TorchAttentionProbe(cfg)\n",
    "probe.fit(train_dataset, val_dataset)\n",
    "\n",
    "# Print val results\n",
    "eval_dict, y_pred, y_pred_proba = probe.eval(val_dataset)\n",
    "print('\\nroc_auc:', eval_dict['roc_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af9fc6",
   "metadata": {},
   "source": [
    "Evaluate the probe on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval against seperate test datasets\n",
    "for new_dataset_name in [\"refusal_llama_3b_1k\", \"refusal_llama_3b_prompted_1k\", \"refusal_ministral_8b_1k\"]:\n",
    "    print(f\"\\nEvaluating on {new_dataset_name}\")\n",
    "    activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(new_dataset_name, layer=cfg.layer, verbose=True)\n",
    "    if probe_type == \"mean\":\n",
    "        activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "    _, _, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, splits=[0, 0, 1000], verbose=True)\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_dict, y_pred, y_pred_proba = probe.eval(test_dataset)\n",
    "    print(eval_dict)\n",
    "    print(classification_report(test_dataset['y'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1cb06",
   "metadata": {},
   "source": [
    "Nice visualisation to see how the probe splits the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ced3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.experiment_plotting import plot_per_class_prediction_distributions\n",
    "\n",
    "plot_per_class_prediction_distributions(test_dataset['y'], y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423e976",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc20327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################### Evaluating layer 6 #############################\n"
     ]
    },
    {
     "ename": "EntryNotFoundError",
     "evalue": "404 Client Error. (Request ID: Root=1-68c83221-5c535ba231c09add0e6be992;2ac4cec7-8ab7-4d1c-93b7-5fe81018c5e6)\n\nEntry Not Found for url: https://huggingface.co/datasets/lasrprobegen/sandbagging-deception-activations/resolve/main/llama_3b_balanced_3.5k_layer_6.pkl.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://huggingface.co/datasets/lasrprobegen/sandbagging-deception-activations/resolve/main/llama_3b_balanced_3.5k_layer_6.pkl",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mEntryNotFoundError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# You might not be able to run all layers at once, so can do them in batches like below\u001b[39;00m\n\u001b[32m     10\u001b[39m layer_list = [\u001b[32m6\u001b[39m,\u001b[32m9\u001b[39m,\u001b[32m12\u001b[39m,\u001b[32m15\u001b[39m,\u001b[32m18\u001b[39m,\u001b[32m21\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mrun_full_hyp_search_on_layers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprobe_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_list\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Need to add hyperparameters to the local json manually\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# # Can load the best params from the search at any time\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# cfg_dict = load_best_params_from_search(\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#     probe_type, dataset_name, model_name, layer_list\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/src/probe_gen/standard_experiments/hyperparameter_search.py:98\u001b[39m, in \u001b[36mrun_full_hyp_search_on_layers\u001b[39m\u001b[34m(probe_type, dataset_name, activations_model, layers_list)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers_list:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m######################### Evaluating layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m #############################\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     activations_tensor, attention_mask, labels_tensor = \u001b[43mprobes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_hf_activations_and_labels_at_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m probe_type:\n\u001b[32m    100\u001b[39m         activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/src/probe_gen/probes/activation_handlers.py:91\u001b[39m, in \u001b[36mload_hf_activations_and_labels_at_layer\u001b[39m\u001b[34m(dataset_name, layer, verbose)\u001b[39m\n\u001b[32m     89\u001b[39m     _download_labels_from_hf(repo_id, labels_filename)\n\u001b[32m     90\u001b[39m labels_tensor = _load_labels_from_local_jsonl(labels_filename, verbose)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m activations_tensor, attention_mask = \u001b[43m_load_activations_from_hf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mactivations_filename_prefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlayer\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m activations_tensor, attention_mask, labels_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/src/probe_gen/probes/activation_handlers.py:41\u001b[39m, in \u001b[36m_load_activations_from_hf\u001b[39m\u001b[34m(repo_id, filename, verbose)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load_activations_from_hf\u001b[39m(repo_id, filename, verbose):\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# Load activations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     file_path = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     df = joblib.load(file_path)\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Extract all activations\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1073\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1069\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[32m   1071\u001b[39m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[32m   1089\u001b[39m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[32m   1090\u001b[39m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1096\u001b[39m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[32m   1097\u001b[39m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1099\u001b[39m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1544\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1545\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m         metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1549\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m   1550\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1551\u001b[39m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[39m\n\u001b[32m   1460\u001b[39m hf_headers[\u001b[33m\"\u001b[39m\u001b[33mAccept-Encoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33midentity\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[32m   1462\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m hf_raise_for_status(r)\n\u001b[32m   1474\u001b[39m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m300\u001b[39m <= response.status_code <= \u001b[32m399\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:310\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m    309\u001b[39m response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(\u001b[32m429\u001b[39m,))\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LASR-probe-gen/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:420\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_code == \u001b[33m\"\u001b[39m\u001b[33mEntryNotFound\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    419\u001b[39m     message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(EntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_code == \u001b[33m\"\u001b[39m\u001b[33mGatedRepo\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    423\u001b[39m     message = (\n\u001b[32m    424\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    425\u001b[39m     )\n",
      "\u001b[31mEntryNotFoundError\u001b[39m: 404 Client Error. (Request ID: Root=1-68c83221-5c535ba231c09add0e6be992;2ac4cec7-8ab7-4d1c-93b7-5fe81018c5e6)\n\nEntry Not Found for url: https://huggingface.co/datasets/lasrprobegen/sandbagging-deception-activations/resolve/main/llama_3b_balanced_3.5k_layer_6.pkl."
     ]
    }
   ],
   "source": [
    "from probe_gen.standard_experiments.hyperparameter_search import run_full_hyp_search_on_layers\n",
    "from probe_gen.standard_experiments.hyperparameter_search import load_best_params_from_search\n",
    "from probe_gen.config import ConfigDict\n",
    "\n",
    "probe_type = \"mean\"\n",
    "dataset_name = \"sandbagging_llama_3b_3.5k\"\n",
    "model_name = \"llama_3b\"\n",
    "\n",
    "# You might not be able to run all layers at once, so can do them in batches like below\n",
    "layer_list = [6,9,12,15,18,21]\n",
    "run_full_hyp_search_on_layers(\n",
    "    probe_type, dataset_name, model_name, layer_list\n",
    ")\n",
    "\n",
    "# Need to add hyperparameters to the local json manually\n",
    "\n",
    "# # Can load the best params from the search at any time\n",
    "# cfg_dict = load_best_params_from_search(\n",
    "#     probe_type, dataset_name, model_name, layer_list\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10af51e",
   "metadata": {},
   "source": [
    "## Testing On-Off Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126890df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mean', 'deception_rp_llama_3b_3.5k'], ['mean', 'deception_rp_llama_3b_prompted_3.5k'], ['mean', 'deception_rp_mistral_7b_3.5k']]\n"
     ]
    }
   ],
   "source": [
    "from probe_gen.config import ConfigDict\n",
    "\n",
    "# Specify rows of probes and columns of tests\n",
    "test_dataset_names = [\n",
    "    'sycophancy_llama_3b_1k',\n",
    "    'sycophancy_llama_3b_prompted_1k',\n",
    "    \"sycophancy_qwen_3b_1k\"\n",
    "]\n",
    "probes_setup = [\n",
    "    ['mean', 'sycophancy_llama_3b_5k'],\n",
    "    ['mean', 'sycophancy_llama_3b_prompted_5k'],\n",
    "    ['mean', 'sycophancy_qwen_3b_5k']\n",
    "]\n",
    "\n",
    "# Can specify hyperparameters for each row if dont want to load best hyperparameters, can also do a mix of specified and not specified\n",
    "# probes_setup = [\n",
    "#     ['mean', 'refusal_llama_3b_5k', ConfigDict(layer=12, use_bias=False, normalize=True, c=0.001)],\n",
    "#     ['mean', 'refusal_llama_3b_prompted_5k'],\n",
    "#     ['mean', 'refusal_ministral_8b_5k', ConfigDict(layer=12, use_bias=False, normalize=True, c=0.001)]\n",
    "# ]\n",
    "\n",
    "print(probes_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313364f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.grid_experiments import run_grid_experiment_lean\n",
    "\n",
    "run_grid_experiment_lean(probes_setup, test_dataset_names, \"llama_3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.grid_experiments import plot_grid_experiment_lean\n",
    "\n",
    "plot_grid_experiment_lean(probes_setup, test_dataset_names, \"llama_3b\", metric=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232acb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.grid_experiments import plot_grid_experiment_lean_with_means\n",
    "from probe_gen.config import TRAIN_AND_TEST_SETS\n",
    "\n",
    "behaviour = ['refusal', 'lists', 'metaphors', 'science','sycophancy_short', 'sycophancy'][5]\n",
    "test_dataset_names = TRAIN_AND_TEST_SETS[behaviour]['test']\n",
    "probes_setup = [['mean', train_set] for train_set in TRAIN_AND_TEST_SETS[behaviour]['train']]\n",
    "\n",
    "\n",
    "plot_grid_experiment_lean_with_means(probes_setup, test_dataset_names, \"llama_3b\", metric=\"roc_auc\", behaviour=behaviour, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17116059",
   "metadata": {},
   "source": [
    "# Old code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.grid_experiments import run_grid_experiment\n",
    "\n",
    "run_grid_experiment(\n",
    "    ['refusal_llama_3b_5k', 'refusal_llama_3b_prompted_5k', \"refusal_ministral_8b_5k\"], \n",
    "    ['refusal_llama_3b_1k', 'refusal_llama_3b_prompted_1k', \"refusal_ministral_8b_1k\"], \n",
    "    [12, 12, 12], # layer\n",
    "    [False, False, False], # use_bias   (one for each row)\n",
    "    [True, True, True], # normalize\n",
    "    [0.001, 0.001, 0.001], # C\n",
    "    \"llama_3b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e710f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.grid_experiments import plot_grid_experiment\n",
    "\n",
    "plot_grid_experiment(\n",
    "    ['refusal_llama_3b_5k', 'refusal_llama_3b_prompted_5k', \"refusal_ministral_8b_5k\"],  \n",
    "    ['refusal_llama_3b_1k', 'refusal_llama_3b_prompted_1k', \"refusal_ministral_8b_1k\"], \n",
    "    ['On (llama)', 'On (llama prompted)', 'Off (ministral)'],\n",
    "    ['On (llama)', 'On (llama prompted)', 'Off (ministral)'],\n",
    "    [12, 12, 12], # layer\n",
    "    [False, False, False], # use_bias   (one for each row)\n",
    "    [True, True, True], # normalize\n",
    "    [0.001, 0.001, 0.001], # C\n",
    "    \"llama_3b\",\n",
    "    \"roc_auc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af489c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.experiment_plotting import plot_results_table\n",
    "\n",
    "plot_results_table(['refusal_5k_on', 'refusal_5k_off_other_model'], 12, 'mean', True, False, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b9f54",
   "metadata": {},
   "source": [
    "## Layer experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ddba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.standard_experiments.layer_experiments import run_layer_experiments\n",
    "\n",
    "use_bias = True\n",
    "normalize_inputs = True\n",
    "\n",
    "run_layer_experiments(\n",
    "    \"mean\",\n",
    "    \"lists_llama_3b_story_5k\",\n",
    "    \"llama_3b\",\n",
    "    1.0, # C\n",
    "    [6, 9, 12, 15, 18], \n",
    "    use_bias_options=[True, False], \n",
    "    normalize_options=[True, False], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d7d10d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'rcParams'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprobe_gen\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstandard_experiments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperiment_plotting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_layer_experiment\n\u001b[32m      3\u001b[39m plot_layer_experiment([\u001b[32m6\u001b[39m, \u001b[32m9\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m15\u001b[39m, \u001b[32m18\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mlists_llama_3b_story_5k\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/src/probe_gen/standard_experiments/experiment_plotting.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/.venv/lib64/python3.11/site-packages/matplotlib/pyplot.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcycler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolorbar\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/.venv/lib64/python3.11/site-packages/matplotlib/colorbar.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmartist\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpatches\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/.venv/lib64/python3.11/site-packages/matplotlib/collections.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, colorizer \u001b[38;5;28;01mas\u001b[39;00m mcolorizer, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors,\n\u001b[32m     22\u001b[39m                _docstring, hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_enums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/.venv/lib64/python3.11/site-packages/matplotlib/lines.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01martist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Artist, allow_rasterization\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     _to_unmasked_float_array, ls_mapper, ls_mapper_r, STEP_LOOKUP_MAP)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmarkers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MarkerStyle\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bbox, BboxTransformTo, TransformedPath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/.venv/lib64/python3.11/site-packages/matplotlib/markers.py:147\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# special-purpose marker identifiers:\u001b[39;00m\n\u001b[32m    143\u001b[39m (TICKLEFT, TICKRIGHT, TICKUP, TICKDOWN,\n\u001b[32m    144\u001b[39m  CARETLEFT, CARETRIGHT, CARETUP, CARETDOWN,\n\u001b[32m    145\u001b[39m  CARETLEFTBASE, CARETRIGHTBASE, CARETUPBASE, CARETDOWNBASE) = \u001b[38;5;28mrange\u001b[39m(\u001b[32m12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m _empty_path = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mMarkerStyle\u001b[39;00m:\n\u001b[32m    151\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[33;03m    A class representing marker types.\u001b[39;00m\n\u001b[32m    153\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m \u001b[33;03m        The supported fillstyles.\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/.venv/lib64/python3.11/site-packages/matplotlib/path.py:152\u001b[39m, in \u001b[36mPath.__init__\u001b[39m\u001b[34m(self, vertices, codes, _interpolation_steps, closed, readonly)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28mself\u001b[39m._codes = codes\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m._interpolation_steps = _interpolation_steps\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m readonly:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._vertices.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/.venv/lib64/python3.11/site-packages/matplotlib/path.py:203\u001b[39m, in \u001b[36mPath._update_values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_values\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28mself\u001b[39m._simplify_threshold = \u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrcParams\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mpath.simplify_threshold\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m._should_simplify = (\n\u001b[32m    205\u001b[39m         \u001b[38;5;28mself\u001b[39m._simplify_threshold > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    206\u001b[39m         mpl.rcParams[\u001b[33m'\u001b[39m\u001b[33mpath.simplify\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    207\u001b[39m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._vertices) >= \u001b[32m128\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    208\u001b[39m         (\u001b[38;5;28mself\u001b[39m._codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m np.all(\u001b[38;5;28mself\u001b[39m._codes <= Path.LINETO))\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LASR-probe-gen/.venv/lib64/python3.11/site-packages/matplotlib/_api/__init__.py:218\u001b[39m, in \u001b[36mcaching_module_getattr.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name].\u001b[34m__get__\u001b[39m(instance)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'matplotlib' has no attribute 'rcParams'"
     ]
    }
   ],
   "source": [
    "from probe_gen.standard_experiments.experiment_plotting import plot_layer_experiment\n",
    "\n",
    "plot_layer_experiment([6, 9, 12, 15, 18], 'lists_llama_3b_story_5k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c56f0",
   "metadata": {},
   "source": [
    "## Compare probe directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb495cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import probe_gen.probes as probes\n",
    "from sklearn.metrics import classification_report\n",
    "from probe_gen.config import ConfigDict\n",
    "\n",
    "# dataset_list = ['refusal_llama_3b_5k', 'refusal_llama_3b_prompted_5k', 'refusal_ministral_8b_5k']\n",
    "# layer_list = [12, 12, 12]\n",
    "# use_bias_list = [False, False, False]\n",
    "# normalize_list = [True, True, True]\n",
    "# C_list = [0.001, 0.001, 0.001]\n",
    "\n",
    "dataset_list = ['lists_llama_3b_5k', 'lists_llama_3b_prompted_5k', 'lists_qwen_3b_5k']\n",
    "layer_list = [9, 12, 12]\n",
    "use_bias_list = [True, True, False]\n",
    "normalize_list = [False, False, False]\n",
    "C_list = [1, 10, 1]\n",
    "\n",
    "# dataset_list = ['metaphors_llama_3b_5k', 'metaphors_llama_3b_prompted_5k', 'metaphors_qwen_3b_5k']\n",
    "# layer_list = [9, 15, 6]\n",
    "# use_bias_list = [False, False, True]\n",
    "# normalize_list = [False, False, False]\n",
    "# C_list = [1, 1, 1]\n",
    "\n",
    "probes_list = []\n",
    "\n",
    "for i in range(len(dataset_list)):\n",
    "    activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(dataset_list[i], layer_list[i], verbose=True)\n",
    "    activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "    # Create train, val, and test datasets\n",
    "    train_dataset, val_dataset, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, val_size=0.1, test_size=0.2, verbose=True)\n",
    "\n",
    "    probe = probes.SklearnLogisticProbe(ConfigDict(use_bias=use_bias_list[i], C=C_list[i], normalize=normalize_list[i]))\n",
    "    probe.fit(train_dataset, val_dataset)\n",
    "    probes_list.append(probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ebc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "biases = []\n",
    "for i in range(len(probes_list)):\n",
    "    weights.append(probes_list[i].classifier.coef_.flatten())\n",
    "    biases.append(probes_list[i].classifier.intercept_.flatten())\n",
    "\n",
    "print(biases)\n",
    "\n",
    "print(cosine_similarity([weights[0]], [weights[1]])[0, 0])\n",
    "print(cosine_similarity([weights[0]], [weights[2]])[0, 0])\n",
    "print(cosine_similarity([weights[1]], [weights[2]])[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import probe_gen.probes as probes\n",
    "from sklearn.metrics import classification_report\n",
    "from probe_gen.config import ConfigDict\n",
    "\n",
    "weights_list = []\n",
    "for i in range(5):\n",
    "    activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(\"refusal_llama_3b_5k\", 12, verbose=True)\n",
    "    activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "    # Create train, val, and test datasets\n",
    "    train_dataset, val_dataset, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, val_size=0.1, test_size=0.2, balance=True, verbose=True)\n",
    "\n",
    "    probe = probes.SklearnLogisticProbe(ConfigDict(use_bias=False, C=0.001, normalize=True))\n",
    "    probe.fit(train_dataset, val_dataset)\n",
    "    weights = probe.classifier.coef_\n",
    "    weights_list.append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.concatenate(weights_list, axis=0)\n",
    "print(weights.var(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895abd0e",
   "metadata": {},
   "source": [
    "## OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake graph\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create the heatmap with seaborn\n",
    "sns.heatmap(\n",
    "    [[0.97,0.924,0.969,0.626], [0.966,0.932,0.96,0.635], [0.968,0.922,0.97,0.6], [0.33,0.345,0.449,0.511]], \n",
    "    xticklabels=['Natural', 'Prompted', 'Other Model', 'Stories'],\n",
    "    yticklabels=['Natural', 'Prompted', 'Other Model', 'Stories'],\n",
    "    annot=True,  # This adds the text annotations\n",
    "    fmt='.2f',   # Format numbers to 3 decimal places\n",
    "    cmap='Greens',  # You can change the colormap\n",
    "    vmin=0.3,\n",
    "    vmax=1,\n",
    "    ax=ax,\n",
    "    annot_kws={\"size\": 20}\n",
    ")\n",
    "\n",
    "# Rotate x-axis labels\n",
    "#plt.xticks(rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Test set', fontsize=14)\n",
    "plt.ylabel('Train set', fontsize=14)\n",
    "ax.set_title(\"Probe (AUROC) Classification of Lists Behaviour in Llama 3B\", fontsize=15)\n",
    "\n",
    "# increase graph size\n",
    "fig.set_size_inches(8, 6)\n",
    "# fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1278804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import probe_gen.probes as probes\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(\"refusal_5k_on\", 12, verbose=True)\n",
    "activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "# Create train, val, and test datasets\n",
    "train_dataset, val_dataset, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, val_size=0, test_size=0.2, balance=True, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c55ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe_gen.config import ConfigDict\n",
    "\n",
    "C_values = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "evals_norm_true_bias_true = []\n",
    "evals_norm_true_bias_false = []\n",
    "evals_norm_false_bias_true = []\n",
    "evals_norm_false_bias_false = []\n",
    "\n",
    "for C in C_values:\n",
    "    print(f\"############ {C} #############\")\n",
    "\n",
    "    probe = probes.SklearnLogisticProbe(ConfigDict(use_bias=True, C=C, normalize=True))\n",
    "    probe.fit(train_dataset, val_dataset)\n",
    "    eval_dict, _, _ = probe.eval(test_dataset)\n",
    "    evals_norm_true_bias_true.append(eval_dict)\n",
    "\n",
    "    probe = probes.SklearnLogisticProbe(ConfigDict(use_bias=False, C=C, normalize=True))\n",
    "    probe.fit(train_dataset, val_dataset)\n",
    "    eval_dict, _, _ = probe.eval(test_dataset)\n",
    "    evals_norm_true_bias_false.append(eval_dict)\n",
    "\n",
    "    probe = probes.SklearnLogisticProbe(ConfigDict(use_bias=True, C=C, normalize=False))\n",
    "    probe.fit(train_dataset, val_dataset)\n",
    "    eval_dict, _, _ = probe.eval(test_dataset)\n",
    "    evals_norm_false_bias_true.append(eval_dict)\n",
    "\n",
    "    probe = probes.SklearnLogisticProbe(ConfigDict(use_bias=False, C=C, normalize=False))\n",
    "    probe.fit(train_dataset, val_dataset)\n",
    "    eval_dict, _, _ = probe.eval(test_dataset)\n",
    "    evals_norm_false_bias_false.append(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3245d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract accuracy and ROC-AUC values for each configuration\n",
    "def extract_metrics(results_list):\n",
    "    accuracy = [result['accuracy'] for result in results_list]\n",
    "    roc_auc = [result['roc_auc'] for result in results_list]\n",
    "    return accuracy, roc_auc\n",
    "\n",
    "# Extract metrics for all configurations\n",
    "acc1, roc1 = extract_metrics(evals_norm_true_bias_true)\n",
    "acc2, roc2 = extract_metrics(evals_norm_true_bias_false)\n",
    "acc3, roc3 = extract_metrics(evals_norm_false_bias_true)\n",
    "acc4, roc4 = extract_metrics(evals_norm_false_bias_false)\n",
    "\n",
    "# Create the plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Define labels for each configuration (modify these based on your actual hyperparameter combinations)\n",
    "config_labels = [\n",
    "    'normalize=True, use_bias=True',  # Replace with actual hyperparameter values, e.g., 'penalty=l2, solver=lbfgs'\n",
    "    'normalize=True, use_bias=False',  # e.g., 'penalty=l2, solver=liblinear'\n",
    "    'normalize=False, use_bias=True',  # e.g., 'penalty=l1, solver=liblinear'\n",
    "    'normalize=False, use_bias=False'   # e.g., 'penalty=elasticnet, solver=saga'\n",
    "]\n",
    "\n",
    "# Plot accuracy (left subplot)\n",
    "ax1.semilogx(C_values, acc1, marker='o', label=config_labels[0])\n",
    "ax1.semilogx(C_values, acc2, marker='s', label=config_labels[1])\n",
    "ax1.semilogx(C_values, acc3, marker='^', label=config_labels[2])\n",
    "ax1.semilogx(C_values, acc4, marker='d', label=config_labels[3])\n",
    "\n",
    "ax1.set_xlabel('C (Inverse Regularization Strength)')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Accuracy vs C')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot ROC-AUC (right subplot)\n",
    "ax2.semilogx(C_values, roc1, marker='o', label=config_labels[0])\n",
    "ax2.semilogx(C_values, roc2, marker='s', label=config_labels[1])\n",
    "ax2.semilogx(C_values, roc3, marker='^', label=config_labels[2])\n",
    "ax2.semilogx(C_values, roc4, marker='d', label=config_labels[3])\n",
    "\n",
    "ax2.set_xlabel('C (Inverse Regularization Strength)')\n",
    "ax2.set_ylabel('ROC-AUC')\n",
    "ax2.set_title('ROC-AUC vs C')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Find and print the best configuration for each metric\n",
    "def find_best_config(metric_lists, config_labels, C_values):\n",
    "    best_scores = []\n",
    "    for i, metrics in enumerate(metric_lists):\n",
    "        best_idx = np.argmax(metrics)\n",
    "        best_scores.append({\n",
    "            'config': config_labels[i],\n",
    "            'best_C': C_values[best_idx],\n",
    "            'best_score': metrics[best_idx]\n",
    "        })\n",
    "    return best_scores\n",
    "\n",
    "# Find best configurations\n",
    "accuracy_lists = [acc1, acc2, acc3, acc4]\n",
    "roc_lists = [roc1, roc2, roc3, roc4]\n",
    "\n",
    "print(\"Best Accuracy Results:\")\n",
    "best_acc = find_best_config(accuracy_lists, config_labels, C_values)\n",
    "for result in best_acc:\n",
    "    print(f\"{result['config']}: C={result['best_C']}, Accuracy={result['best_score']:.4f}\")\n",
    "\n",
    "print(\"\\nBest ROC-AUC Results:\")\n",
    "best_roc = find_best_config(roc_lists, config_labels, C_values)\n",
    "for result in best_roc:\n",
    "    print(f\"{result['config']}: C={result['best_C']}, ROC-AUC={result['best_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
