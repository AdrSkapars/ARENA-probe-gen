{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b38c53",
   "metadata": {},
   "source": [
    "## Train probe\n",
    "- Goal: To train MVP probes on activations\n",
    "    - Maybe make those probes be fancy (mean, attention, softmax)\n",
    "    - Maybe make those activations be real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20bb32e",
   "metadata": {},
   "source": [
    "### Do probe training (HF dataset activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729248f5",
   "metadata": {},
   "source": [
    "Load the activations and labels from HF, aggregate, and construct datasets to train the probe on (note sklearn doesn't require a validation dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419d46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import probe_gen.probes as probes\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fe1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e481af0f9940219da314f14ef823df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "refusal_meta-llama_Llama-3.2-3B-Instruct(â€¦):   0%|          | 0.00/7.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/lasr-tutorial/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the activations and labels from hf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m activations_tensor, labels_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mprobes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_hf_activations_and_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNLie2/anthropic-refusal-activations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrefusal_meta-llama_Llama-3.2-3B-Instruct__on_policy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Aggregate the activations\u001b[39;00m\n\u001b[1;32m      4\u001b[0m activations_tensor \u001b[38;5;241m=\u001b[39m probes\u001b[38;5;241m.\u001b[39mMeanAggregation()(activations_tensor)\n",
      "File \u001b[0;32m~/lasr-tutorial/src/probe_gen/probes/activation_handlers.py:50\u001b[0m, in \u001b[0;36mload_hf_activations_and_labels\u001b[0;34m(repo_id, filename, layer)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Load activations\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(file_path)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Extract all activations\u001b[39;00m\n",
      "File \u001b[0;32m~/lasr-tutorial/.venv/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lasr-tutorial/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    992\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lasr-tutorial/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1171\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/lasr-tutorial/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1723\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1722\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1723\u001b[0m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m~/lasr-tutorial/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the activations and labels from hf\n",
    "activations_tensor, labels_tensor = probes.load_hf_activations_and_labels(\"NLie2/anthropic-refusal-activations\", \"refusal_meta-llama_Llama-3.2-3B-Instruct__on_policy\", 13)\n",
    "# Aggregate the activations\n",
    "activations_tensor = probes.MeanAggregation()(activations_tensor)\n",
    "# Create train, val, and test datasets\n",
    "train_dataset, val_dataset, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, val_size=0, test_size=0.2, balance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e80507",
   "metadata": {},
   "source": [
    "Create a probe and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be293935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise and fit a probe with the datasets\n",
    "probe = probes.SklearnLogisticProbe(use_bias=False)\n",
    "probe.fit(train_dataset, val_dataset, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af9fc6",
   "metadata": {},
   "source": [
    "Evaluate the probe on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26fc8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = probe.predict(test_dataset['X'])\n",
    "y_pred_proba = probe.predict_proba(test_dataset['X'])  # probabilities for class 1\n",
    "\n",
    "# Evaluate the model\n",
    "eval_dict = probe.eval(test_dataset)\n",
    "print(eval_dict)\n",
    "print(type(classification_report(test_dataset['y'], y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1cb06",
   "metadata": {},
   "source": [
    "Nice visualisation to see how the probe splits the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de150007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.hist(y_pred_proba[test_dataset['y'].numpy() == 0], alpha=0.5, label='Complied', bins=20)\n",
    "plt.hist(y_pred_proba[test_dataset['y'].numpy() == 1], alpha=0.5, label='Rejected', bins=20)\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.title('Prediction Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d303b",
   "metadata": {},
   "source": [
    "# Torch training (not yet integrated / needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb13be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now actually train the probe on training data and evaluate on test data\n",
    "import matplotlib.pyplot as plt\n",
    "from probe_gen.probe_train import train_probe, evaluate_probe\n",
    "\n",
    "print(\"Training linear probe...\")\n",
    "print(f\"Train data: {train_activations.shape}, Val data: {val_activations.shape}\")\n",
    "\n",
    "# Train probe\n",
    "model, train_losses, val_losses = train_probe(\n",
    "    train_activations=train_activations,\n",
    "    train_labels=train_labels,\n",
    "    val_activations=val_activations,\n",
    "    val_labels=val_labels,\n",
    "    probe_type=\"mean\",\n",
    "    learning_rate=5e-3,\n",
    "    batch_size=16,\n",
    "    num_epochs=100,\n",
    "    early_stop_patience=20,\n",
    "    silent=True\n",
    ")\n",
    "\n",
    "# Evaluate probe\n",
    "print(\"\\nEvaluating probe...\")\n",
    "results = evaluate_probe(model, test_activations, test_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {results['accuracy']:.4f}\")\n",
    "print(f\"Test AUC-ROC: {results['auc_roc']:.4f}\")\n",
    "print(f\"TPR at 1% FPR: {results['tpr_at_1_fpr']:.4f}\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Curves')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(results['probabilities'][test_labels.numpy() == 0], alpha=0.5, label='Complied', bins=20)\n",
    "plt.hist(results['probabilities'][test_labels.numpy() == 1], alpha=0.5, label='Rejected', bins=20)\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.title('Prediction Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# Show some values\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "for i in range(10):\n",
    "    logits = model(train_activations[i:i+1,:,:])\n",
    "    print(train_labels[i], logits[0])\n",
    "    print(torch.sigmoid(logits[0]))\n",
    "    print(torch.sigmoid(logits[0]) > 0.5)\n",
    "    print(criterion(logits[0], train_labels[i].float()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd74a7",
   "metadata": {},
   "source": [
    "### Do probe experiments (HF dataset activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94002ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from huggingface_hub import hf_hub_download\n",
    "from probe_gen.probe_train import train_probe, evaluate_probe\n",
    "\n",
    "for layer_num in range(5):\n",
    "    print(f\"\\n\\nLayer {layer_num}\")\n",
    "    # Load the labels\n",
    "    labels_list = []\n",
    "    with open(\"../data/refusal/on_policy_raw.jsonl\", 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            if data[\"scale_labels\"] <= 5:\n",
    "                labels_list.append(1.0)\n",
    "            else:\n",
    "                labels_list.append(0.0)\n",
    "    labels_tensor = torch.tensor(labels_list)\n",
    "    print(\"loaded labels\")\n",
    "\n",
    "    # Load activations\n",
    "    file_path = hf_hub_download(\n",
    "        repo_id=\"NLie2/anthropic-refusal-activations\",\n",
    "        filename=\"dataframe_with_activations.pkl\",\n",
    "        repo_type=\"dataset\")\n",
    "    df = pd.read_pickle(file_path)\n",
    "    print(f\"loaded activations, with shape: {df.shape}\")\n",
    "\n",
    "    # Extract all activations\n",
    "    all_activations = []\n",
    "    for i in range(len(df)):\n",
    "        all_activations.append(df.loc[i][\"activations\"][0])\n",
    "    activations_tensor = torch.cat(all_activations, dim=0).unsqueeze(1).to(torch.float32)\n",
    "\n",
    "    # Get indices for each label\n",
    "    label_0_indices = (labels_tensor == 0.0).nonzero(as_tuple=True)[0]\n",
    "    label_1_indices = (labels_tensor == 1.0).nonzero(as_tuple=True)[0]\n",
    "    min_class_count = min(len(label_0_indices), len(label_1_indices))\n",
    "\n",
    "    # Subsample both classes to same size\n",
    "    label_0_indices = label_0_indices[:min_class_count]\n",
    "    label_1_indices = label_1_indices[:min_class_count]\n",
    "\n",
    "    # Shuffle indices\n",
    "    label_0_indices = label_0_indices[torch.randperm(len(label_0_indices))]\n",
    "    label_1_indices = label_1_indices[torch.randperm(len(label_1_indices))]\n",
    "\n",
    "    # Compute split sizes\n",
    "    n_total = min_class_count\n",
    "    n_train = int(0.8 * n_total)\n",
    "    n_val = int(0.1 * n_total)\n",
    "    n_test = n_total - n_train - n_val\n",
    "\n",
    "    # Split label 0s\n",
    "    train_0 = label_0_indices[:n_train]\n",
    "    val_0 = label_0_indices[n_train:n_train + n_val]\n",
    "    test_0 = label_0_indices[n_train + n_val:]\n",
    "\n",
    "    # Split label 1s\n",
    "    train_1 = label_1_indices[:n_train]\n",
    "    val_1 = label_1_indices[n_train:n_train + n_val]\n",
    "    test_1 = label_1_indices[n_train + n_val:]\n",
    "\n",
    "    # Concatenate splits and shuffle within each\n",
    "    def get_split(indices_0, indices_1):\n",
    "        indices = torch.cat([indices_0, indices_1])\n",
    "        indices = indices[torch.randperm(len(indices))]\n",
    "        return activations_tensor[indices], labels_tensor[indices]\n",
    "\n",
    "    train_activations, train_labels = get_split(train_0, train_1)\n",
    "    val_activations, val_labels = get_split(val_0, val_1)\n",
    "    test_activations, test_labels = get_split(test_0, test_1)\n",
    "\n",
    "    # Confirm balance\n",
    "    print(f\"Train: {train_labels.shape[0]} samples, {train_labels.sum()} positives\")\n",
    "    print(f\"Val:   {val_labels.shape[0]} samples, {val_labels.sum()} positives\")\n",
    "    print(f\"Test:  {test_labels.shape[0]} samples, {test_labels.sum()} positives\")\n",
    "\n",
    "    # Now actually train the probe on training data and evaluate on test data\n",
    "\n",
    "    print(\"Training linear probe...\")\n",
    "    print(f\"Train data: {train_activations.shape}, Val data: {val_activations.shape}\")\n",
    "\n",
    "    # Train probe\n",
    "    model, train_losses, val_losses = train_probe(\n",
    "        train_activations=train_activations,\n",
    "        train_labels=train_labels,\n",
    "        val_activations=val_activations,\n",
    "        val_labels=val_labels,\n",
    "        probe_type=\"mean\",\n",
    "        learning_rate=5e-3,\n",
    "        batch_size=16,\n",
    "        num_epochs=100,\n",
    "        early_stop_patience=20,\n",
    "        silent=True\n",
    "    )\n",
    "\n",
    "    # Evaluate probe\n",
    "    print(\"\\nEvaluating probe...\")\n",
    "    results = evaluate_probe(model, test_activations, test_labels)\n",
    "\n",
    "    print(\"Test Accuracy, Test AUC-ROC, TPR at 1% FPR\")\n",
    "    print(f\"{results['accuracy']:.4f}\\t{results['auc_roc']:.4f}\\t{results['tpr_at_1_fpr']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
