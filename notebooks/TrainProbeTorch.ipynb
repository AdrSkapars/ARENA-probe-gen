{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20bb32e",
   "metadata": {},
   "source": [
    "# Do probe training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729248f5",
   "metadata": {},
   "source": [
    "Load the activations and labels from HF, aggregate, and construct datasets to train the probe on (note sklearn doesn't require a validation dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fe1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels\n",
      "loaded activations with shape torch.Size([5000, 337, 3072])\n",
      "calculated attention mask with shape torch.Size([5000, 337])\n",
      "Train: 3500 samples, 1750.0 positives\n",
      "Val:   500 samples, 250.0 positives\n",
      "Test:  1000 samples, 500.0 positives\n"
     ]
    }
   ],
   "source": [
    "import probe_gen.probes as probes\n",
    "from sklearn.metrics import classification_report\n",
    "from probe_gen.config import ConfigDict\n",
    "\n",
    "layer = 12\n",
    "probe_type = [\"mean_torch\", \"attention_torch\"][1]\n",
    "\n",
    "# Create train, val, and test datasets\n",
    "activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(\"refusal_llama_3b_5k\", layer=layer, verbose=True)\n",
    "if probe_type == \"mean_torch\":\n",
    "    activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "train_dataset, val_dataset, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, val_size=0.1, test_size=0.2, balance=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc2e182",
   "metadata": {},
   "source": [
    "Create a probe and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "364c5b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100, Train Loss: 0.3058, Val Loss: 0.3383\n",
      "Epoch 20/100, Train Loss: 0.2619, Val Loss: 0.3300\n",
      "\n",
      "roc_auc: 0.9354560000000001\n"
     ]
    }
   ],
   "source": [
    "# Initialise and fit a probe with the datasets\n",
    "cfg = ConfigDict(use_bias=True, normalize=True, lr=0.0001, weight_decay=0.0)\n",
    "if probe_type == \"mean_torch\":\n",
    "    probe = probes.TorchLinearProbe(cfg)\n",
    "elif probe_type == \"attention_torch\":\n",
    "    probe = probes.TorchAttentionProbe(cfg)\n",
    "probe.fit(train_dataset, val_dataset)\n",
    "\n",
    "# Print val results\n",
    "eval_dict, y_pred, y_pred_proba = probe.eval(val_dataset)\n",
    "print('\\nroc_auc:', eval_dict['roc_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af9fc6",
   "metadata": {},
   "source": [
    "Evaluate the probe on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392df070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.876, 'roc_auc': 0.934068, 'tpr_at_1_fpr': np.float64(0.3)}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.87      0.88       500\n",
      "         1.0       0.87      0.88      0.88       500\n",
      "\n",
      "    accuracy                           0.88      1000\n",
      "   macro avg       0.88      0.88      0.88      1000\n",
      "weighted avg       0.88      0.88      0.88      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_dict, y_pred, y_pred_proba = probe.eval(test_dataset)\n",
    "print(eval_dict)\n",
    "print(classification_report(test_dataset['y'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43e7080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded activations with shape torch.Size([1000, 249, 3072])\n",
      "calculated attention mask with shape torch.Size([1000, 249])\n",
      "Train: 0 samples, 0.0 positives\n",
      "Val:   0 samples, 0.0 positives\n",
      "Test:  1000 samples, 500.0 positives\n",
      "{'accuracy': 0.858, 'roc_auc': 0.91186, 'tpr_at_1_fpr': np.float64(0.104)}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.83      0.85       500\n",
      "         1.0       0.84      0.88      0.86       500\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a seperate test dataset\n",
    "activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(\"refusal_llama_3b_1k\", layer=layer, verbose=True)\n",
    "if probe_type == \"mean_torch\":\n",
    "    activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "_, _, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, val_size=0.0, test_size=1.0, balance=True, verbose=True)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_dict, y_pred, y_pred_proba = probe.eval(test_dataset)\n",
    "print(eval_dict)\n",
    "print(classification_report(test_dataset['y'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c2c9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded activations with shape torch.Size([1000, 249, 3072])\n",
      "calculated attention mask with shape torch.Size([1000, 249])\n",
      "Train: 0 samples, 0.0 positives\n",
      "Val:   0 samples, 0.0 positives\n",
      "Test:  1000 samples, 500.0 positives\n",
      "{'accuracy': 0.857, 'roc_auc': 0.90416, 'tpr_at_1_fpr': np.float64(0.058)}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.80      0.85       500\n",
      "         1.0       0.82      0.91      0.86       500\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.86      0.86      0.86      1000\n",
      "weighted avg       0.86      0.86      0.86      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a seperate test dataset\n",
    "activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(\"refusal_llama_3b_prompted_1k\", layer=layer, verbose=True)\n",
    "if probe_type == \"mean_torch\":\n",
    "    activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "_, _, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, val_size=0.0, test_size=1.0, balance=True, verbose=True)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_dict, y_pred, y_pred_proba = probe.eval(test_dataset)\n",
    "print(eval_dict)\n",
    "print(classification_report(test_dataset['y'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc94755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels\n",
      "loaded activations with shape torch.Size([1000, 248, 3072])\n",
      "calculated attention mask with shape torch.Size([1000, 248])\n",
      "Train: 0 samples, 0.0 positives\n",
      "Val:   0 samples, 0.0 positives\n",
      "Test:  1000 samples, 500.0 positives\n",
      "{'accuracy': 0.851, 'roc_auc': 0.912976, 'tpr_at_1_fpr': np.float64(0.112)}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.83      0.85       500\n",
      "         1.0       0.83      0.88      0.85       500\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a seperate test dataset\n",
    "activations_tensor, attention_mask, labels_tensor = probes.load_hf_activations_and_labels_at_layer(\"refusal_ministral_8b_1k\", layer=layer, verbose=True)\n",
    "if probe_type == \"mean_torch\":\n",
    "    activations_tensor = probes.MeanAggregation()(activations_tensor, attention_mask)\n",
    "_, _, test_dataset = probes.create_activation_datasets(activations_tensor, labels_tensor, val_size=0.0, test_size=1.0, balance=True, verbose=True)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_dict, y_pred, y_pred_proba = probe.eval(test_dataset)\n",
    "print(eval_dict)\n",
    "print(classification_report(test_dataset['y'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf0729",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea67ea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################### Evaluating layer 6 #############################\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3491, Val Loss: 0.3851\n",
      "Epoch 20/100, Train Loss: 0.3133, Val Loss: 0.3706\n",
      "Epoch 30/100, Train Loss: 0.2890, Val Loss: 0.3668\n",
      "Epoch 40/100, Train Loss: 0.2738, Val Loss: 0.3644\n",
      "Epoch 50/100, Train Loss: 0.2606, Val Loss: 0.3648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100, Train Loss: 0.3491, Val Loss: 0.3851\n",
      "Epoch 20/100, Train Loss: 0.3133, Val Loss: 0.3706\n",
      "Epoch 30/100, Train Loss: 0.2890, Val Loss: 0.3668\n",
      "Epoch 40/100, Train Loss: 0.2738, Val Loss: 0.3644\n",
      "Epoch 50/100, Train Loss: 0.2606, Val Loss: 0.3648\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3491, Val Loss: 0.3851\n",
      "Epoch 20/100, Train Loss: 0.3133, Val Loss: 0.3706\n",
      "Epoch 30/100, Train Loss: 0.2890, Val Loss: 0.3668\n",
      "Epoch 40/100, Train Loss: 0.2738, Val Loss: 0.3644\n",
      "Epoch 50/100, Train Loss: 0.2606, Val Loss: 0.3648\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3491, Val Loss: 0.3851\n",
      "Epoch 20/100, Train Loss: 0.3133, Val Loss: 0.3706\n",
      "Epoch 30/100, Train Loss: 0.2890, Val Loss: 0.3668\n",
      "Epoch 40/100, Train Loss: 0.2739, Val Loss: 0.3644\n",
      "Epoch 50/100, Train Loss: 0.2607, Val Loss: 0.3648\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3491, Val Loss: 0.3851\n",
      "Epoch 20/100, Train Loss: 0.3136, Val Loss: 0.3706\n",
      "Epoch 30/100, Train Loss: 0.2895, Val Loss: 0.3668\n",
      "Epoch 40/100, Train Loss: 0.2746, Val Loss: 0.3644\n",
      "Epoch 50/100, Train Loss: 0.2618, Val Loss: 0.3646\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3497, Val Loss: 0.3852\n",
      "Epoch 20/100, Train Loss: 0.3158, Val Loss: 0.3709\n",
      "Epoch 30/100, Train Loss: 0.2941, Val Loss: 0.3674\n",
      "Epoch 40/100, Train Loss: 0.2822, Val Loss: 0.3648\n",
      "Epoch 50/100, Train Loss: 0.2727, Val Loss: 0.3645\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2677, Val Loss: 0.3681\n",
      "Epoch 20/100, Train Loss: 0.2224, Val Loss: 0.3752\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2677, Val Loss: 0.3681\n",
      "Epoch 20/100, Train Loss: 0.2224, Val Loss: 0.3752\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2677, Val Loss: 0.3681\n",
      "Epoch 20/100, Train Loss: 0.2224, Val Loss: 0.3752\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2678, Val Loss: 0.3681\n",
      "Epoch 20/100, Train Loss: 0.2227, Val Loss: 0.3750\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2686, Val Loss: 0.3680\n",
      "Epoch 20/100, Train Loss: 0.2255, Val Loss: 0.3736\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2777, Val Loss: 0.3675\n",
      "Epoch 20/100, Train Loss: 0.2507, Val Loss: 0.3670\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2294, Val Loss: 0.3783\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2294, Val Loss: 0.3783\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2294, Val Loss: 0.3782\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2296, Val Loss: 0.3781\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2321, Val Loss: 0.3769\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2554, Val Loss: 0.3710\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1569, Val Loss: 0.5237\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1569, Val Loss: 0.5237\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1571, Val Loss: 0.5233\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1589, Val Loss: 0.5198\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1772, Val Loss: 0.4921\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2924, Val Loss: 0.4339\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1743, Val Loss: 0.7140\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1743, Val Loss: 0.7138\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1745, Val Loss: 0.7125\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1769, Val Loss: 0.7006\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2152, Val Loss: 0.6679\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.4143, Val Loss: 0.6026\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6111, Val Loss: 2.8498\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7296, Val Loss: 3.1677\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6752, Val Loss: 2.8474\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.8504, Val Loss: 2.9517\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.2870, Val Loss: 2.4283\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.3036, Val Loss: 1.6990\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.4611, Val Loss: 6.8847\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.2116, Val Loss: 5.5488\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.2113, Val Loss: 5.4997\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.5649, Val Loss: 4.5240\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.9433, Val Loss: 4.7381\n",
      "Epoch 20/100, Train Loss: 2.8587, Val Loss: 4.0258\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.2559, Val Loss: 3.4313\n",
      "\n",
      "######################### Evaluating layer 9 #############################\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3344, Val Loss: 0.3626\n",
      "Epoch 20/100, Train Loss: 0.2983, Val Loss: 0.3475\n",
      "Epoch 30/100, Train Loss: 0.2762, Val Loss: 0.3437\n",
      "Epoch 40/100, Train Loss: 0.2625, Val Loss: 0.3418\n",
      "Epoch 50/100, Train Loss: 0.2499, Val Loss: 0.3426\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3344, Val Loss: 0.3626\n",
      "Epoch 20/100, Train Loss: 0.2983, Val Loss: 0.3475\n",
      "Epoch 30/100, Train Loss: 0.2762, Val Loss: 0.3437\n",
      "Epoch 40/100, Train Loss: 0.2625, Val Loss: 0.3418\n",
      "Epoch 50/100, Train Loss: 0.2499, Val Loss: 0.3426\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3344, Val Loss: 0.3626\n",
      "Epoch 20/100, Train Loss: 0.2983, Val Loss: 0.3475\n",
      "Epoch 30/100, Train Loss: 0.2762, Val Loss: 0.3437\n",
      "Epoch 40/100, Train Loss: 0.2625, Val Loss: 0.3418\n",
      "Epoch 50/100, Train Loss: 0.2499, Val Loss: 0.3425\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3344, Val Loss: 0.3626\n",
      "Epoch 20/100, Train Loss: 0.2983, Val Loss: 0.3475\n",
      "Epoch 30/100, Train Loss: 0.2762, Val Loss: 0.3437\n",
      "Epoch 40/100, Train Loss: 0.2626, Val Loss: 0.3418\n",
      "Epoch 50/100, Train Loss: 0.2500, Val Loss: 0.3425\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3344, Val Loss: 0.3626\n",
      "Epoch 20/100, Train Loss: 0.2985, Val Loss: 0.3475\n",
      "Epoch 30/100, Train Loss: 0.2767, Val Loss: 0.3437\n",
      "Epoch 40/100, Train Loss: 0.2633, Val Loss: 0.3416\n",
      "Epoch 50/100, Train Loss: 0.2511, Val Loss: 0.3422\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3348, Val Loss: 0.3625\n",
      "Epoch 20/100, Train Loss: 0.3007, Val Loss: 0.3477\n",
      "Epoch 30/100, Train Loss: 0.2811, Val Loss: 0.3438\n",
      "Epoch 40/100, Train Loss: 0.2704, Val Loss: 0.3412\n",
      "Epoch 50/100, Train Loss: 0.2615, Val Loss: 0.3411\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2573, Val Loss: 0.3432\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2573, Val Loss: 0.3432\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2573, Val Loss: 0.3432\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2574, Val Loss: 0.3432\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2582, Val Loss: 0.3430\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2668, Val Loss: 0.3423\n",
      "Epoch 20/100, Train Loss: 0.2399, Val Loss: 0.3415\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2215, Val Loss: 0.3508\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2215, Val Loss: 0.3508\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2215, Val Loss: 0.3507\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2218, Val Loss: 0.3506\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2241, Val Loss: 0.3492\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2463, Val Loss: 0.3431\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1541, Val Loss: 0.4881\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1542, Val Loss: 0.4881\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1543, Val Loss: 0.4877\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1562, Val Loss: 0.4846\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1740, Val Loss: 0.4596\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2821, Val Loss: 0.4067\n",
      "Epoch 20/100, Train Loss: 0.2885, Val Loss: 0.4592\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1740, Val Loss: 0.7073\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1740, Val Loss: 0.7071\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1741, Val Loss: 0.7056\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1747, Val Loss: 0.6904\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2035, Val Loss: 0.5975\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3843, Val Loss: 0.5832\n",
      "Epoch 20/100, Train Loss: 0.3927, Val Loss: 0.5316\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6988, Val Loss: 2.9418\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7686, Val Loss: 3.1283\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6566, Val Loss: 3.1001\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7813, Val Loss: 2.5472\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.1664, Val Loss: 2.9466\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.5002, Val Loss: 2.4261\n",
      "Epoch 20/100, Train Loss: 1.4472, Val Loss: 2.1143\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.3049, Val Loss: 5.9025\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.6899, Val Loss: 5.9441\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.4606, Val Loss: 6.0330\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.7151, Val Loss: 5.3356\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.6625, Val Loss: 3.7549\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.3442, Val Loss: 2.9093\n",
      "\n",
      "######################### Evaluating layer 12 #############################\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3222, Val Loss: 0.3460\n",
      "Epoch 20/100, Train Loss: 0.2892, Val Loss: 0.3327\n",
      "Epoch 30/100, Train Loss: 0.2689, Val Loss: 0.3307\n",
      "Epoch 40/100, Train Loss: 0.2549, Val Loss: 0.3302\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3222, Val Loss: 0.3460\n",
      "Epoch 20/100, Train Loss: 0.2892, Val Loss: 0.3327\n",
      "Epoch 30/100, Train Loss: 0.2689, Val Loss: 0.3307\n",
      "Epoch 40/100, Train Loss: 0.2549, Val Loss: 0.3302\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3222, Val Loss: 0.3460\n",
      "Epoch 20/100, Train Loss: 0.2892, Val Loss: 0.3327\n",
      "Epoch 30/100, Train Loss: 0.2690, Val Loss: 0.3307\n",
      "Epoch 40/100, Train Loss: 0.2549, Val Loss: 0.3302\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3222, Val Loss: 0.3460\n",
      "Epoch 20/100, Train Loss: 0.2892, Val Loss: 0.3327\n",
      "Epoch 30/100, Train Loss: 0.2690, Val Loss: 0.3307\n",
      "Epoch 40/100, Train Loss: 0.2549, Val Loss: 0.3302\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3222, Val Loss: 0.3460\n",
      "Epoch 20/100, Train Loss: 0.2894, Val Loss: 0.3328\n",
      "Epoch 30/100, Train Loss: 0.2694, Val Loss: 0.3307\n",
      "Epoch 40/100, Train Loss: 0.2556, Val Loss: 0.3301\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3227, Val Loss: 0.3463\n",
      "Epoch 20/100, Train Loss: 0.2915, Val Loss: 0.3335\n",
      "Epoch 30/100, Train Loss: 0.2737, Val Loss: 0.3314\n",
      "Epoch 40/100, Train Loss: 0.2627, Val Loss: 0.3304\n",
      "Epoch 50/100, Train Loss: 0.2552, Val Loss: 0.3307\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2521, Val Loss: 0.3336\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2521, Val Loss: 0.3336\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2521, Val Loss: 0.3336\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2521, Val Loss: 0.3336\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2529, Val Loss: 0.3334\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2610, Val Loss: 0.3331\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2184, Val Loss: 0.3430\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2184, Val Loss: 0.3430\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2184, Val Loss: 0.3430\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2187, Val Loss: 0.3428\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2209, Val Loss: 0.3415\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2421, Val Loss: 0.3353\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1517, Val Loss: 0.4530\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1518, Val Loss: 0.4530\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1519, Val Loss: 0.4527\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1538, Val Loss: 0.4502\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1718, Val Loss: 0.4318\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2776, Val Loss: 0.3964\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1732, Val Loss: 0.6327\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1733, Val Loss: 0.6327\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1738, Val Loss: 0.6320\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1793, Val Loss: 0.6258\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2236, Val Loss: 0.5658\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3828, Val Loss: 0.5361\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7884, Val Loss: 2.6591\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6405, Val Loss: 2.5163\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.5715, Val Loss: 2.1629\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7089, Val Loss: 1.9999\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.4430, Val Loss: 2.2502\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.2560, Val Loss: 1.5276\n",
      "Epoch 20/100, Train Loss: 1.5021, Val Loss: 1.6124\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.4932, Val Loss: 4.7860\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.5456, Val Loss: 5.6194\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.4422, Val Loss: 4.6321\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.1572, Val Loss: 4.6546\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.5866, Val Loss: 4.2827\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.6595, Val Loss: 4.1143\n",
      "\n",
      "######################### Evaluating layer 15 #############################\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3278, Val Loss: 0.3694\n",
      "Epoch 20/100, Train Loss: 0.2941, Val Loss: 0.3511\n",
      "Epoch 30/100, Train Loss: 0.2727, Val Loss: 0.3445\n",
      "Epoch 40/100, Train Loss: 0.2594, Val Loss: 0.3404\n",
      "Epoch 50/100, Train Loss: 0.2482, Val Loss: 0.3392\n",
      "Epoch 60/100, Train Loss: 0.2397, Val Loss: 0.3396\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3278, Val Loss: 0.3694\n",
      "Epoch 20/100, Train Loss: 0.2941, Val Loss: 0.3511\n",
      "Epoch 30/100, Train Loss: 0.2727, Val Loss: 0.3445\n",
      "Epoch 40/100, Train Loss: 0.2594, Val Loss: 0.3404\n",
      "Epoch 50/100, Train Loss: 0.2482, Val Loss: 0.3392\n",
      "Epoch 60/100, Train Loss: 0.2397, Val Loss: 0.3396\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3278, Val Loss: 0.3694\n",
      "Epoch 20/100, Train Loss: 0.2941, Val Loss: 0.3511\n",
      "Epoch 30/100, Train Loss: 0.2727, Val Loss: 0.3445\n",
      "Epoch 40/100, Train Loss: 0.2594, Val Loss: 0.3404\n",
      "Epoch 50/100, Train Loss: 0.2482, Val Loss: 0.3392\n",
      "Epoch 60/100, Train Loss: 0.2397, Val Loss: 0.3396\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3278, Val Loss: 0.3694\n",
      "Epoch 20/100, Train Loss: 0.2942, Val Loss: 0.3511\n",
      "Epoch 30/100, Train Loss: 0.2727, Val Loss: 0.3445\n",
      "Epoch 40/100, Train Loss: 0.2595, Val Loss: 0.3404\n",
      "Epoch 50/100, Train Loss: 0.2483, Val Loss: 0.3391\n",
      "Epoch 60/100, Train Loss: 0.2399, Val Loss: 0.3395\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3279, Val Loss: 0.3694\n",
      "Epoch 20/100, Train Loss: 0.2944, Val Loss: 0.3510\n",
      "Epoch 30/100, Train Loss: 0.2732, Val Loss: 0.3444\n",
      "Epoch 40/100, Train Loss: 0.2602, Val Loss: 0.3402\n",
      "Epoch 50/100, Train Loss: 0.2494, Val Loss: 0.3388\n",
      "Epoch 60/100, Train Loss: 0.2412, Val Loss: 0.3391\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3284, Val Loss: 0.3688\n",
      "Epoch 20/100, Train Loss: 0.2966, Val Loss: 0.3504\n",
      "Epoch 30/100, Train Loss: 0.2778, Val Loss: 0.3439\n",
      "Epoch 40/100, Train Loss: 0.2677, Val Loss: 0.3395\n",
      "Epoch 50/100, Train Loss: 0.2598, Val Loss: 0.3377\n",
      "Epoch 60/100, Train Loss: 0.2546, Val Loss: 0.3372\n",
      "Epoch 70/100, Train Loss: 0.2442, Val Loss: 0.3364\n",
      "Epoch 80/100, Train Loss: 0.2434, Val Loss: 0.3362\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2555, Val Loss: 0.3428\n",
      "Epoch 20/100, Train Loss: 0.2130, Val Loss: 0.3436\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2555, Val Loss: 0.3428\n",
      "Epoch 20/100, Train Loss: 0.2130, Val Loss: 0.3436\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2555, Val Loss: 0.3428\n",
      "Epoch 20/100, Train Loss: 0.2131, Val Loss: 0.3436\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2556, Val Loss: 0.3428\n",
      "Epoch 20/100, Train Loss: 0.2133, Val Loss: 0.3434\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2565, Val Loss: 0.3424\n",
      "Epoch 20/100, Train Loss: 0.2160, Val Loss: 0.3419\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2653, Val Loss: 0.3409\n",
      "Epoch 20/100, Train Loss: 0.2404, Val Loss: 0.3356\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2224, Val Loss: 0.3465\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2224, Val Loss: 0.3465\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2224, Val Loss: 0.3465\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2227, Val Loss: 0.3464\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2250, Val Loss: 0.3449\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2473, Val Loss: 0.3382\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1535, Val Loss: 0.4372\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1536, Val Loss: 0.4372\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1538, Val Loss: 0.4369\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1559, Val Loss: 0.4341\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1768, Val Loss: 0.4141\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2956, Val Loss: 0.3935\n",
      "Epoch 20/100, Train Loss: 0.2917, Val Loss: 0.4263\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1715, Val Loss: 0.5626\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1716, Val Loss: 0.5625\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1723, Val Loss: 0.5619\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1791, Val Loss: 0.5563\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2317, Val Loss: 0.5287\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.4013, Val Loss: 0.5126\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7704, Val Loss: 2.3803\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7244, Val Loss: 2.3619\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7370, Val Loss: 2.1958\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7036, Val Loss: 1.9821\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.3578, Val Loss: 1.9472\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.4149, Val Loss: 2.2093\n",
      "Epoch 20/100, Train Loss: 1.2724, Val Loss: 1.2913\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.1288, Val Loss: 4.0243\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.1988, Val Loss: 4.5365\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.5390, Val Loss: 4.3841\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.8846, Val Loss: 4.4115\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.7360, Val Loss: 4.1320\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.3265, Val Loss: 2.9898\n",
      "\n",
      "######################### Evaluating layer 18 #############################\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3320, Val Loss: 0.3767\n",
      "Epoch 20/100, Train Loss: 0.2961, Val Loss: 0.3570\n",
      "Epoch 30/100, Train Loss: 0.2737, Val Loss: 0.3491\n",
      "Epoch 40/100, Train Loss: 0.2599, Val Loss: 0.3445\n",
      "Epoch 50/100, Train Loss: 0.2486, Val Loss: 0.3435\n",
      "Epoch 60/100, Train Loss: 0.2398, Val Loss: 0.3441\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3320, Val Loss: 0.3767\n",
      "Epoch 20/100, Train Loss: 0.2961, Val Loss: 0.3570\n",
      "Epoch 30/100, Train Loss: 0.2737, Val Loss: 0.3491\n",
      "Epoch 40/100, Train Loss: 0.2599, Val Loss: 0.3445\n",
      "Epoch 50/100, Train Loss: 0.2486, Val Loss: 0.3435\n",
      "Epoch 60/100, Train Loss: 0.2398, Val Loss: 0.3441\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3320, Val Loss: 0.3767\n",
      "Epoch 20/100, Train Loss: 0.2961, Val Loss: 0.3570\n",
      "Epoch 30/100, Train Loss: 0.2737, Val Loss: 0.3491\n",
      "Epoch 40/100, Train Loss: 0.2600, Val Loss: 0.3445\n",
      "Epoch 50/100, Train Loss: 0.2486, Val Loss: 0.3435\n",
      "Epoch 60/100, Train Loss: 0.2398, Val Loss: 0.3441\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3320, Val Loss: 0.3766\n",
      "Epoch 20/100, Train Loss: 0.2962, Val Loss: 0.3569\n",
      "Epoch 30/100, Train Loss: 0.2738, Val Loss: 0.3491\n",
      "Epoch 40/100, Train Loss: 0.2600, Val Loss: 0.3445\n",
      "Epoch 50/100, Train Loss: 0.2487, Val Loss: 0.3434\n",
      "Epoch 60/100, Train Loss: 0.2400, Val Loss: 0.3440\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3321, Val Loss: 0.3765\n",
      "Epoch 20/100, Train Loss: 0.2964, Val Loss: 0.3568\n",
      "Epoch 30/100, Train Loss: 0.2742, Val Loss: 0.3489\n",
      "Epoch 40/100, Train Loss: 0.2608, Val Loss: 0.3442\n",
      "Epoch 50/100, Train Loss: 0.2497, Val Loss: 0.3430\n",
      "Epoch 60/100, Train Loss: 0.2413, Val Loss: 0.3434\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3326, Val Loss: 0.3757\n",
      "Epoch 20/100, Train Loss: 0.2986, Val Loss: 0.3556\n",
      "Epoch 30/100, Train Loss: 0.2788, Val Loss: 0.3477\n",
      "Epoch 40/100, Train Loss: 0.2682, Val Loss: 0.3427\n",
      "Epoch 50/100, Train Loss: 0.2600, Val Loss: 0.3409\n",
      "Epoch 60/100, Train Loss: 0.2544, Val Loss: 0.3405\n",
      "Epoch 70/100, Train Loss: 0.2436, Val Loss: 0.3397\n",
      "Epoch 80/100, Train Loss: 0.2423, Val Loss: 0.3392\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2546, Val Loss: 0.3457\n",
      "Epoch 20/100, Train Loss: 0.2116, Val Loss: 0.3475\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2546, Val Loss: 0.3457\n",
      "Epoch 20/100, Train Loss: 0.2116, Val Loss: 0.3475\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2546, Val Loss: 0.3457\n",
      "Epoch 20/100, Train Loss: 0.2117, Val Loss: 0.3475\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2547, Val Loss: 0.3456\n",
      "Epoch 20/100, Train Loss: 0.2119, Val Loss: 0.3473\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2556, Val Loss: 0.3452\n",
      "Epoch 20/100, Train Loss: 0.2146, Val Loss: 0.3457\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2643, Val Loss: 0.3431\n",
      "Epoch 20/100, Train Loss: 0.2388, Val Loss: 0.3384\n",
      "Epoch 30/100, Train Loss: 0.2293, Val Loss: 0.3438\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2199, Val Loss: 0.3511\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2199, Val Loss: 0.3511\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2199, Val Loss: 0.3511\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2202, Val Loss: 0.3509\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2224, Val Loss: 0.3493\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2445, Val Loss: 0.3414\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1499, Val Loss: 0.4550\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1499, Val Loss: 0.4550\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1501, Val Loss: 0.4546\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1522, Val Loss: 0.4511\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1733, Val Loss: 0.4250\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2943, Val Loss: 0.3941\n",
      "Epoch 20/100, Train Loss: 0.2911, Val Loss: 0.4435\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1792, Val Loss: 0.6041\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1793, Val Loss: 0.6040\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1799, Val Loss: 0.6033\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1866, Val Loss: 0.5965\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2467, Val Loss: 0.5477\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.4162, Val Loss: 0.5182\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6853, Val Loss: 2.4106\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6818, Val Loss: 2.3369\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6274, Val Loss: 2.3531\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7969, Val Loss: 2.0481\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.4501, Val Loss: 2.1521\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.4579, Val Loss: 1.7813\n",
      "Epoch 20/100, Train Loss: 1.3161, Val Loss: 1.3845\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.9630, Val Loss: 4.7891\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.1581, Val Loss: 4.7232\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.3799, Val Loss: 4.7317\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.8610, Val Loss: 4.1685\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.7283, Val Loss: 3.6088\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.6902, Val Loss: 2.0726\n",
      "\n",
      "######################### Evaluating layer 21 #############################\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3363, Val Loss: 0.3788\n",
      "Epoch 20/100, Train Loss: 0.2987, Val Loss: 0.3615\n",
      "Epoch 30/100, Train Loss: 0.2748, Val Loss: 0.3551\n",
      "Epoch 40/100, Train Loss: 0.2609, Val Loss: 0.3513\n",
      "Epoch 50/100, Train Loss: 0.2489, Val Loss: 0.3503\n",
      "Epoch 60/100, Train Loss: 0.2390, Val Loss: 0.3506\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3363, Val Loss: 0.3788\n",
      "Epoch 20/100, Train Loss: 0.2987, Val Loss: 0.3615\n",
      "Epoch 30/100, Train Loss: 0.2748, Val Loss: 0.3551\n",
      "Epoch 40/100, Train Loss: 0.2609, Val Loss: 0.3513\n",
      "Epoch 50/100, Train Loss: 0.2489, Val Loss: 0.3503\n",
      "Epoch 60/100, Train Loss: 0.2390, Val Loss: 0.3506\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3363, Val Loss: 0.3788\n",
      "Epoch 20/100, Train Loss: 0.2987, Val Loss: 0.3615\n",
      "Epoch 30/100, Train Loss: 0.2748, Val Loss: 0.3551\n",
      "Epoch 40/100, Train Loss: 0.2609, Val Loss: 0.3513\n",
      "Epoch 50/100, Train Loss: 0.2489, Val Loss: 0.3503\n",
      "Epoch 60/100, Train Loss: 0.2390, Val Loss: 0.3506\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3363, Val Loss: 0.3788\n",
      "Epoch 20/100, Train Loss: 0.2987, Val Loss: 0.3615\n",
      "Epoch 30/100, Train Loss: 0.2749, Val Loss: 0.3551\n",
      "Epoch 40/100, Train Loss: 0.2610, Val Loss: 0.3513\n",
      "Epoch 50/100, Train Loss: 0.2490, Val Loss: 0.3503\n",
      "Epoch 60/100, Train Loss: 0.2392, Val Loss: 0.3505\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3364, Val Loss: 0.3787\n",
      "Epoch 20/100, Train Loss: 0.2990, Val Loss: 0.3613\n",
      "Epoch 30/100, Train Loss: 0.2754, Val Loss: 0.3549\n",
      "Epoch 40/100, Train Loss: 0.2618, Val Loss: 0.3510\n",
      "Epoch 50/100, Train Loss: 0.2501, Val Loss: 0.3499\n",
      "Epoch 60/100, Train Loss: 0.2406, Val Loss: 0.3500\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3370, Val Loss: 0.3782\n",
      "Epoch 20/100, Train Loss: 0.3014, Val Loss: 0.3605\n",
      "Epoch 30/100, Train Loss: 0.2803, Val Loss: 0.3539\n",
      "Epoch 40/100, Train Loss: 0.2696, Val Loss: 0.3497\n",
      "Epoch 50/100, Train Loss: 0.2610, Val Loss: 0.3479\n",
      "Epoch 60/100, Train Loss: 0.2545, Val Loss: 0.3471\n",
      "Epoch 70/100, Train Loss: 0.2442, Val Loss: 0.3466\n",
      "Epoch 80/100, Train Loss: 0.2428, Val Loss: 0.3461\n",
      "Epoch 90/100, Train Loss: 0.2366, Val Loss: 0.3454\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2544, Val Loss: 0.3521\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2544, Val Loss: 0.3521\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2544, Val Loss: 0.3521\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2545, Val Loss: 0.3520\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2554, Val Loss: 0.3516\n",
      "Epoch 20/100, Train Loss: 0.2136, Val Loss: 0.3517\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2649, Val Loss: 0.3496\n",
      "Epoch 20/100, Train Loss: 0.2391, Val Loss: 0.3443\n",
      "Epoch 30/100, Train Loss: 0.2291, Val Loss: 0.3483\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2187, Val Loss: 0.3552\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2187, Val Loss: 0.3552\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2187, Val Loss: 0.3552\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2189, Val Loss: 0.3550\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2214, Val Loss: 0.3534\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2450, Val Loss: 0.3461\n",
      "Epoch 20/100, Train Loss: 0.2320, Val Loss: 0.3476\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1499, Val Loss: 0.4500\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1500, Val Loss: 0.4500\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1502, Val Loss: 0.4496\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1524, Val Loss: 0.4462\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1737, Val Loss: 0.4220\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2949, Val Loss: 0.3923\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1749, Val Loss: 0.6180\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1749, Val Loss: 0.6179\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1756, Val Loss: 0.6170\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.1821, Val Loss: 0.6090\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.2470, Val Loss: 0.5449\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.4396, Val Loss: 0.5018\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.5309, Val Loss: 2.2936\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.6621, Val Loss: 2.7669\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.7633, Val Loss: 2.5872\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.9549, Val Loss: 2.5229\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.3134, Val Loss: 1.8597\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.5193, Val Loss: 1.6706\n",
      "Epoch 20/100, Train Loss: 1.1576, Val Loss: 1.5521\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.0985, Val Loss: 4.3094\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.1567, Val Loss: 4.3562\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.0965, Val Loss: 5.0352\n",
      "\n",
      "Epoch 10/100, Train Loss: 1.6716, Val Loss: 3.8441\n",
      "\n",
      "Epoch 10/100, Train Loss: 3.0500, Val Loss: 3.2098\n",
      "\n",
      "Epoch 10/100, Train Loss: 2.4366, Val Loss: 2.3018\n",
      "Epoch 20/100, Train Loss: 2.5855, Val Loss: 2.6571\n",
      "Epoch 30/100, Train Loss: 2.8500, Val Loss: 2.5693\n",
      "Epoch 40/100, Train Loss: 2.8779, Val Loss: 2.7500\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.4741\n",
      "Epoch 20/100, Train Loss: 0.4198\n",
      "Epoch 30/100, Train Loss: 0.3956\n",
      "Epoch 40/100, Train Loss: 0.3796\n",
      "Epoch 50/100, Train Loss: 0.3658\n",
      "Epoch 60/100, Train Loss: 0.3602\n",
      "Epoch 70/100, Train Loss: 0.3475\n",
      "Epoch 80/100, Train Loss: 0.3478\n",
      "Epoch 90/100, Train Loss: 0.3361\n",
      "Epoch 100/100, Train Loss: 0.3314\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.3368\n",
      "Epoch 20/100, Train Loss: 0.2983\n",
      "Epoch 30/100, Train Loss: 0.2755\n",
      "Epoch 40/100, Train Loss: 0.2611\n",
      "Epoch 50/100, Train Loss: 0.2468\n",
      "Epoch 60/100, Train Loss: 0.2366\n",
      "Epoch 70/100, Train Loss: 0.2267\n",
      "Epoch 80/100, Train Loss: 0.2205\n",
      "Epoch 90/100, Train Loss: 0.2110\n",
      "Epoch 100/100, Train Loss: 0.2047\n",
      "\n",
      "Epoch 10/100, Train Loss: 0.4715\n",
      "Epoch 20/100, Train Loss: 0.4171\n",
      "Epoch 30/100, Train Loss: 0.3927\n",
      "Epoch 40/100, Train Loss: 0.3794\n",
      "Epoch 50/100, Train Loss: 0.3656\n",
      "Epoch 60/100, Train Loss: 0.3568\n",
      "Epoch 70/100, Train Loss: 0.3496\n",
      "Epoch 80/100, Train Loss: 0.3458\n",
      "Epoch 90/100, Train Loss: 0.3385\n",
      "Epoch 100/100, Train Loss: 0.3326\n",
      "\n",
      "Best Params, Layer: 12, LR: 0.0001, Weight Decay: 0, Normalize: True, Use Bias: True\n",
      "Best roc_auc: 0.928752\n"
     ]
    }
   ],
   "source": [
    "from probe_gen.standard_experiments.hyperparameter_search import run_full_hyp_search_on_layers\n",
    "\n",
    "# You might not be able to run all layers at once, so can do them in batches like below\n",
    "run_full_hyp_search_on_layers(\n",
    "    'attention_torch', 'refusal_llama_3b_5k', 'llama_3b', [6,9,12,15,18,21]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb899629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best roc_auc: 0.928752\n",
      "Best params: {'layer': 12, 'lr': 0.0001, 'use_bias': True, 'normalize': True, 'weight_decay': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from probe_gen.standard_experiments.hyperparameter_search import load_best_params_from_search\n",
    "\n",
    "# Can load the best params from the search at any time\n",
    "load_best_params_from_search(\n",
    "    'attention_torch', 'refusal_llama_3b_5k', 'llama_3b', [6,9,12,15,18,21]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
