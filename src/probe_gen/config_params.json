{
    "attention_torch": {
        "deception_deepseek_mixtral_3.5k": {
            "layer": 12,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.01
        },
        "deception_llama_3b_3.5k": {
            "layer": 12,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.01
        },
        "deception_llama_3b_prompted_3.5k": {
            "layer": 12,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.01
        },
        "refusal_llama_3b_5k": {
            "layer": 12,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.0
        },
        "refusal_llama_3b_prompted_5k": {
            "layer": 12,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.1
        },
        "refusal_ministral_8b_5k": {
            "layer": 15,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.1
        },
        "sycophancy_llama_3b_4k": {
            "layer": 12,
            "lr": 0.0005,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.0
        },
        "sycophancy_llama_3b_prompted_4k": {
            "layer": 12,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.1
        },
        "sycophancy_ministral_8b_4k": {
            "layer": 15,
            "lr": 0.001,
            "normalize": true,
            "use_bias": false,
            "weight_decay": 0.01
        },
        "sycophancy_short_llama_3b_4k": {
            "layer": 12,
            "lr": 0.0005,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.01
        },
        "sycophancy_short_llama_3b_prompted_4k": {
            "layer": 12,
            "lr": 0.0005,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.01
        },
        "sycophancy_short_qwen_3b_4k": {
            "layer": 12,
            "lr": 0.0005,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.1
        }
    },
    "mean": {
        "lists": {
            "C": 0.01,
            "layer": 12
        },
        "metaphors": {
            "C": 0.01,
            "layer": 12
        },
        "refusal": {
            "C": 0.001,
            "layer": 12
        },
        "science": {
            "C": 0.01,
            "layer": 12
        },
        "sycophancy": {
            "C": 0.01,
            "layer": 12
        },
        "authority": {
            "C": 0.001,
            "layer": 12
        },
        "deception": {
            "C": 0.001,
            "layer": 9
        },
        "deception_rp": {
            "C": 0.1,
            "layer": 12
        },
        "sandbagging": {
            "C": 0.01,
            "layer": 12
        },
        "sandbagging_multi": {
            "C": 0.001,
            "layer": 12
        }
    },
    "mean_torch": {
        "refusal_llama_3b_5k": {
            "layer": 12,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.0
        },
        "refusal_llama_3b_prompted_5k": {
            "layer": 12,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.0
        },
        "refusal_ministral_8b_5k": {
            "layer": 15,
            "lr": 0.0001,
            "normalize": true,
            "use_bias": true,
            "weight_decay": 0.1
        }
    }
}